{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9230a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "from utils.schema import KnowledgeGraph\n",
    "from utils.prompts import SYSTEM_PROMPT, PROMPT\n",
    "from utils.kg import create_graph\n",
    "from utils.llm_utils import llm, unload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f9528",
   "metadata": {},
   "source": [
    " ./llama-swap/build/llama-swap-linux-amd64 --config utils/config.yaml --listen localhost:8888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205b4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_TO_TEST = [\n",
    "    \"mistral-small-sd\",    # 24B + 0.5B\n",
    "    \"gemma3-sd\",           # 27B + 1B\n",
    "    \"qwen3-sd\",            # 32B + 0.6B\n",
    "]\n",
    "\n",
    "HOST = '192.168.0.252'\n",
    "# HOST = 'localhost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef93d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = r\"\"\"\n",
    "AI Styria by AI Austria ‚Äì Machine Learning Graz Meetup: Summer Edition 2025\n",
    "\n",
    "After an extended break, the Machine Learning Graz Meetup is back - more dynamic and exciting than ever! AI Austria and Wirecube have teamed up to reignite Styria‚Äôs ML community. Whether you're active in research, industry, or simply curious about ML, Data Science, and AI - this meetup is perfect for you!\n",
    "\n",
    "When & Where:\n",
    "üìÖ Tuesday, July 8, 2025, Start 5:00 PM\n",
    "üìç Wirecube Graz ‚Äì Waagner-Biro-Stra√üe 124/4th floor, 8020 Graz\n",
    "\n",
    "Program:\n",
    "\n",
    "- 6:15 PM ‚Äì Welcome & Introduction\n",
    "- Andreas Windisch (Joanneum Research): \"Research Meets Industry ‚Äì Hands-on ML Use Case\"\n",
    "- Roman Kern, David Fleischhacker (Know-Center): \"Go Trustworthy, Go Local\"\n",
    "- Florian Becker (CEO Wirecube): \"Predictive Maintenance ‚Äì ML in Operational Use\"\n",
    "- Thomas Kloiber (VP AI, Leftshift One): \"Deep Dive into RAG Agents ‚Äì Technology & Application\"\n",
    "- 8:00 PM ‚Äì Open Q&A Session & Food, Drinks & Networking üçïüçªü§ù\n",
    "\n",
    "Join us, save the date, and actively engage in shaping the future of Graz's Machine Learning community at the AI Austria Meetup Summer Edition 2025!\n",
    "\"\"\"\n",
    "\n",
    "prompt = PROMPT.format(text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901259aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**mistral-small-sd:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/mistral-small-sd.html\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**gemma3-sd:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/gemma3-sd.html\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**qwen3-sd:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/qwen3-sd.html\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_metrics = []\n",
    "\n",
    "for model_name in MODELS_TO_TEST:\n",
    "    display(Markdown(f\"**{model_name}:**\"))\n",
    "    \n",
    "    unload(host=HOST)\n",
    "    response, metrics = llm(model_name, system=SYSTEM_PROMPT, prompt=prompt, schema=KnowledgeGraph, host=HOST)\n",
    "    unload(host=HOST)\n",
    "    all_metrics.append(metrics)\n",
    "    \n",
    "    kg_name = f\"output/{model_name}.html\"\n",
    "    knowledge_graph = create_graph(response)\n",
    "    knowledge_graph.show(kg_name)\n",
    "    \n",
    "    display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d09284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+---------------------+--------------------+-----------------+----------------------+\n",
      "| Model            |   Token Generation |   Prompt Processing |   Tokens Generated |   Tokens Prompt |   Draft Accept Ratio |\n",
      "|                  |         (tokens/s) |          (tokens/s) |                    |                 |                      |\n",
      "+==================+====================+=====================+====================+=================+======================+\n",
      "| mistral-small-sd |             160.76 |             4235.98 |               1714 |            1156 |                 0.83 |\n",
      "+------------------+--------------------+---------------------+--------------------+-----------------+----------------------+\n",
      "| gemma3-sd        |             108.98 |             3384.8  |               1919 |            1193 |                 0.73 |\n",
      "+------------------+--------------------+---------------------+--------------------+-----------------+----------------------+\n",
      "| qwen3-sd         |             102.65 |             3081.13 |                893 |            1136 |                 0.74 |\n",
      "+------------------+--------------------+---------------------+--------------------+-----------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "summary_headers = [\"Model\", \"Token Generation\\n(tokens/s)\", \"Prompt Processing\\n(tokens/s)\", \"Tokens Generated\", \"Tokens Prompt\", \"Draft Accept Ratio\"]\n",
    "print(tabulate(all_metrics, headers=summary_headers, tablefmt=\"grid\")) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
